{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_description</th>\n",
       "      <th>state_info</th>\n",
       "      <th>true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_false_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13847</td>\n",
       "      <td>5</td>\n",
       "      <td>90 percent of Americans \"support universal bac...</td>\n",
       "      <td>October 2, 2017</td>\n",
       "      <td>government regulation;polls and public opinion...</td>\n",
       "      <td>chris abele</td>\n",
       "      <td>Chris Abele is Milwaukee County Executive, a p...</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>a tweet</td>\n",
       "      <td>\"Universal\" is the term for background checks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13411</td>\n",
       "      <td>1</td>\n",
       "      <td>Last year was one of the deadliest years ever ...</td>\n",
       "      <td>May 19, 2017</td>\n",
       "      <td>after the fact;congress;criminal justice;histo...</td>\n",
       "      <td>thom tillis</td>\n",
       "      <td>Thom Tillis is a Republican who serves as U.S....</td>\n",
       "      <td>north carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a press release supporting the Back The Blue A...</td>\n",
       "      <td>Sen. Thom Tillis, a North Carolina Republican,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10882</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernie Sanders's plan is \"to raise your taxes ...</td>\n",
       "      <td>October 28, 2015</td>\n",
       "      <td>taxes</td>\n",
       "      <td>chris christie</td>\n",
       "      <td>Chris Christie announced June 6, 2023 that he ...</td>\n",
       "      <td>national</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>Boulder, Colo</td>\n",
       "      <td>Christie said that Sanders’s plan is \"to raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20697</td>\n",
       "      <td>4</td>\n",
       "      <td>Voter ID is supported by an overwhelming major...</td>\n",
       "      <td>December 8, 2021</td>\n",
       "      <td>voter id laws</td>\n",
       "      <td>lee zeldin</td>\n",
       "      <td>Lee Zeldin is a Republican representing New Yo...</td>\n",
       "      <td>new york</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a Tweet</td>\n",
       "      <td>Zeldin claimed voter identification requiremen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6095</td>\n",
       "      <td>2</td>\n",
       "      <td>Says Barack Obama \"robbed Medicare (of) $716 b...</td>\n",
       "      <td>August 12, 2012</td>\n",
       "      <td>federal budget;history;medicare;retirement</td>\n",
       "      <td>mitt romney</td>\n",
       "      <td>Mitt Romney is a U.S. senator from Utah. He ra...</td>\n",
       "      <td>national</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>an interview on \"60 Minutes\"</td>\n",
       "      <td>Romney said, \"There's only one president that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                          statement  \\\n",
       "0  13847      5  90 percent of Americans \"support universal bac...   \n",
       "1  13411      1  Last year was one of the deadliest years ever ...   \n",
       "2  10882      0  Bernie Sanders's plan is \"to raise your taxes ...   \n",
       "3  20697      4  Voter ID is supported by an overwhelming major...   \n",
       "4   6095      2  Says Barack Obama \"robbed Medicare (of) $716 b...   \n",
       "\n",
       "               date                                            subject  \\\n",
       "0   October 2, 2017  government regulation;polls and public opinion...   \n",
       "1      May 19, 2017  after the fact;congress;criminal justice;histo...   \n",
       "2  October 28, 2015                                              taxes   \n",
       "3  December 8, 2021                                      voter id laws   \n",
       "4   August 12, 2012         federal budget;history;medicare;retirement   \n",
       "\n",
       "          speaker                                speaker_description  \\\n",
       "0     chris abele  Chris Abele is Milwaukee County Executive, a p...   \n",
       "1     thom tillis  Thom Tillis is a Republican who serves as U.S....   \n",
       "2  chris christie  Chris Christie announced June 6, 2023 that he ...   \n",
       "3      lee zeldin  Lee Zeldin is a Republican representing New Yo...   \n",
       "4     mitt romney  Mitt Romney is a U.S. senator from Utah. He ra...   \n",
       "\n",
       "       state_info  true_counts  mostly_true_counts  half_true_counts  \\\n",
       "0       wisconsin            1                   4                 5   \n",
       "1  north carolina            0                   2                 7   \n",
       "2        national           21                  20                27   \n",
       "3        new york            1                   2                 0   \n",
       "4        national           31                  33                58   \n",
       "\n",
       "   mostly_false_counts  false_counts  pants_on_fire_counts  \\\n",
       "0                    3             5                     2   \n",
       "1                    3             2                     0   \n",
       "2                   11            17                     8   \n",
       "3                    0             0                     0   \n",
       "4                   35            32                    19   \n",
       "\n",
       "                                             context  \\\n",
       "0                                            a tweet   \n",
       "1  a press release supporting the Back The Blue A...   \n",
       "2                                      Boulder, Colo   \n",
       "3                                            a Tweet   \n",
       "4                       an interview on \"60 Minutes\"   \n",
       "\n",
       "                                       justification  \n",
       "0  \"Universal\" is the term for background checks ...  \n",
       "1  Sen. Thom Tillis, a North Carolina Republican,...  \n",
       "2  Christie said that Sanders’s plan is \"to raise...  \n",
       "3  Zeldin claimed voter identification requiremen...  \n",
       "4  Romney said, \"There's only one president that ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainData = pd.read_csv(\"LIAR2/train.csv\", delimiter=',')\n",
    "trainData['statement'] = trainData['statement'].astype(str)\n",
    "statements = trainData['statement'].tolist()\n",
    "\n",
    "display(trainData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>8362</td>\n",
       "      <td>-1_the_to_says_and</td>\n",
       "      <td>[the, to, says, and, of, for, in, that, is, on]</td>\n",
       "      <td>[Says Trump told Fox News \"the Democrats can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>807</td>\n",
       "      <td>0_school_schools_education_college</td>\n",
       "      <td>[school, schools, education, college, students...</td>\n",
       "      <td>[Says that despite a recent increase in school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>407</td>\n",
       "      <td>1_abortion_parenthood_planned_abortions</td>\n",
       "      <td>[abortion, parenthood, planned, abortions, wom...</td>\n",
       "      <td>[Says Wisconsin Gov. Tony Evers \"wants to forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>239</td>\n",
       "      <td>2_ballots_election_fraud_mail</td>\n",
       "      <td>[ballots, election, fraud, mail, voter, arizon...</td>\n",
       "      <td>[Ballots in Arizona's Maricopa County\" from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>219</td>\n",
       "      <td>3_biden_joe_video_shows</td>\n",
       "      <td>[biden, joe, video, shows, bidens, president, ...</td>\n",
       "      <td>[Video shows Joe Biden has a body double., Say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>236</td>\n",
       "      <td>10</td>\n",
       "      <td>236_deficit_trillion_decade_took</td>\n",
       "      <td>[deficit, trillion, decade, took, oneyear, map...</td>\n",
       "      <td>[Deficit spending 'exploded during the Obama a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>237</td>\n",
       "      <td>10</td>\n",
       "      <td>237_georgias_georgia_investments_film</td>\n",
       "      <td>[georgias, georgia, investments, film, industr...</td>\n",
       "      <td>[The  Georgia Department of Economic Developme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>238</td>\n",
       "      <td>10</td>\n",
       "      <td>238_rainy_fund_day_226</td>\n",
       "      <td>[rainy, fund, day, 226, 643, lawmakers, 201213...</td>\n",
       "      <td>[Thanks to our policies, \"for the first time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>239</td>\n",
       "      <td>10</td>\n",
       "      <td>239_davis_wendy_ayotte_cheese</td>\n",
       "      <td>[davis, wendy, ayotte, cheese, socialists, kel...</td>\n",
       "      <td>[Says Wendy Davis, \"born into difficult circum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>240</td>\n",
       "      <td>10</td>\n",
       "      <td>240_welfare_meanstested_immigrants_benefits</td>\n",
       "      <td>[welfare, meanstested, immigrants, benefits, o...</td>\n",
       "      <td>[When it comes to how many of the 35 different...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                         Name  \\\n",
       "0       -1   8362                           -1_the_to_says_and   \n",
       "1        0    807           0_school_schools_education_college   \n",
       "2        1    407      1_abortion_parenthood_planned_abortions   \n",
       "3        2    239                2_ballots_election_fraud_mail   \n",
       "4        3    219                      3_biden_joe_video_shows   \n",
       "..     ...    ...                                          ...   \n",
       "237    236     10             236_deficit_trillion_decade_took   \n",
       "238    237     10        237_georgias_georgia_investments_film   \n",
       "239    238     10                       238_rainy_fund_day_226   \n",
       "240    239     10                239_davis_wendy_ayotte_cheese   \n",
       "241    240     10  240_welfare_meanstested_immigrants_benefits   \n",
       "\n",
       "                                        Representation  \\\n",
       "0      [the, to, says, and, of, for, in, that, is, on]   \n",
       "1    [school, schools, education, college, students...   \n",
       "2    [abortion, parenthood, planned, abortions, wom...   \n",
       "3    [ballots, election, fraud, mail, voter, arizon...   \n",
       "4    [biden, joe, video, shows, bidens, president, ...   \n",
       "..                                                 ...   \n",
       "237  [deficit, trillion, decade, took, oneyear, map...   \n",
       "238  [georgias, georgia, investments, film, industr...   \n",
       "239  [rainy, fund, day, 226, 643, lawmakers, 201213...   \n",
       "240  [davis, wendy, ayotte, cheese, socialists, kel...   \n",
       "241  [welfare, meanstested, immigrants, benefits, o...   \n",
       "\n",
       "                                   Representative_Docs  \n",
       "0    [Says Trump told Fox News \"the Democrats can s...  \n",
       "1    [Says that despite a recent increase in school...  \n",
       "2    [Says Wisconsin Gov. Tony Evers \"wants to forc...  \n",
       "3    [Ballots in Arizona's Maricopa County\" from th...  \n",
       "4    [Video shows Joe Biden has a body double., Say...  \n",
       "..                                                 ...  \n",
       "237  [Deficit spending 'exploded during the Obama a...  \n",
       "238  [The  Georgia Department of Economic Developme...  \n",
       "239  [Thanks to our policies, \"for the first time i...  \n",
       "240  [Says Wendy Davis, \"born into difficult circum...  \n",
       "241  [When it comes to how many of the 35 different...  \n",
       "\n",
       "[242 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No finetuning used\n",
    "# Initialize BERTopic model\n",
    "topic_model = BERTopic()\n",
    "# Fit the model on the statements\n",
    "topics, probs = topic_model.fit_transform(statements)\n",
    "\n",
    "# To view the topics and their frequencies\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"LIAR2/train.csv\", delimiter=',')\n",
    "\n",
    "# Filter necessary columns and drop missing values\n",
    "data = data[['statement', 'subject']].dropna()\n",
    "\n",
    "# Encode 'subject' as numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['subject'] = label_encoder.fit_transform(data['subject'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['statement'], data['subject'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize BERTopic model with BERT embeddings\n",
    "topic_model = BERTopic(embedding_model=\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Fit the model on training data statements\n",
    "topics, probabilities = topic_model.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7016</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "      <td>[the, to, of, and, in, for, says, that, is, has]</td>\n",
       "      <td>[House Speaker Nancy Pelosi said this week tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>691</td>\n",
       "      <td>0_school_schools_education_scott</td>\n",
       "      <td>[school, schools, education, scott, students, ...</td>\n",
       "      <td>[Teachers in Chicago Public Schools are paid s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>1_covid_19_vaccine_vaccines</td>\n",
       "      <td>[covid, 19, vaccine, vaccines, vaccinated, cdc...</td>\n",
       "      <td>[White House, CDC, WHO and vaccine makers don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>325</td>\n",
       "      <td>2_biden_joe_shows_video</td>\n",
       "      <td>[biden, joe, shows, video, president, hunter, ...</td>\n",
       "      <td>[Document shows that Hunter Biden paid Joe Bid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "      <td>3_ballots_election_voter_voting</td>\n",
       "      <td>[ballots, election, voter, voting, mail, vote,...</td>\n",
       "      <td>[November 2012 was \"a record year of turnout. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>94</td>\n",
       "      <td>19</td>\n",
       "      <td>94_jersey_new_job_christie</td>\n",
       "      <td>[jersey, new, job, christie, jobs, growth, cre...</td>\n",
       "      <td>[When it comes to being effective at creating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>95</td>\n",
       "      <td>19</td>\n",
       "      <td>95_trafficking_human_camps_central</td>\n",
       "      <td>[trafficking, human, camps, central, task, cag...</td>\n",
       "      <td>[Because of the Trans-Pacific Partnership \"we'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>96_china_korea_north_communists</td>\n",
       "      <td>[china, korea, north, communists, elections, w...</td>\n",
       "      <td>[It's an absolute fact\" that China and North K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>97</td>\n",
       "      <td>18</td>\n",
       "      <td>97_returns_released_tax_release</td>\n",
       "      <td>[returns, released, tax, release, return, romn...</td>\n",
       "      <td>[Mitt Romney is the first major party candidat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>98</td>\n",
       "      <td>18</td>\n",
       "      <td>98_coal_emissions_greenhouse_power</td>\n",
       "      <td>[coal, emissions, greenhouse, power, carbon, g...</td>\n",
       "      <td>[The United States had 589 coal-fired plants 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                Name  \\\n",
       "0      -1   7016                    -1_the_to_of_and   \n",
       "1       0    691    0_school_schools_education_scott   \n",
       "2       1    362         1_covid_19_vaccine_vaccines   \n",
       "3       2    325             2_biden_joe_shows_video   \n",
       "4       3    312     3_ballots_election_voter_voting   \n",
       "..    ...    ...                                 ...   \n",
       "95     94     19          94_jersey_new_job_christie   \n",
       "96     95     19  95_trafficking_human_camps_central   \n",
       "97     96     18     96_china_korea_north_communists   \n",
       "98     97     18     97_returns_released_tax_release   \n",
       "99     98     18  98_coal_emissions_greenhouse_power   \n",
       "\n",
       "                                       Representation  \\\n",
       "0    [the, to, of, and, in, for, says, that, is, has]   \n",
       "1   [school, schools, education, scott, students, ...   \n",
       "2   [covid, 19, vaccine, vaccines, vaccinated, cdc...   \n",
       "3   [biden, joe, shows, video, president, hunter, ...   \n",
       "4   [ballots, election, voter, voting, mail, vote,...   \n",
       "..                                                ...   \n",
       "95  [jersey, new, job, christie, jobs, growth, cre...   \n",
       "96  [trafficking, human, camps, central, task, cag...   \n",
       "97  [china, korea, north, communists, elections, w...   \n",
       "98  [returns, released, tax, release, return, romn...   \n",
       "99  [coal, emissions, greenhouse, power, carbon, g...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [House Speaker Nancy Pelosi said this week tha...  \n",
       "1   [Teachers in Chicago Public Schools are paid s...  \n",
       "2   [White House, CDC, WHO and vaccine makers don'...  \n",
       "3   [Document shows that Hunter Biden paid Joe Bid...  \n",
       "4   [November 2012 was \"a record year of turnout. ...  \n",
       "..                                                ...  \n",
       "95  [When it comes to being effective at creating ...  \n",
       "96  [Because of the Trans-Pacific Partnership \"we'...  \n",
       "97  [It's an absolute fact\" that China and North K...  \n",
       "98  [Mitt Romney is the first major party candidat...  \n",
       "99  [The United States had 589 coal-fired plants 1...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve topics and their representations\n",
    "topic_info = topic_model.get_topic_info()\n",
    "display(topic_info.head(100))\n",
    "\n",
    "# Map each topic to the actual subject label, if a pattern exists\n",
    "# Alternatively, use embeddings to train a classifier (next step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"LIAR2/train.csv\")\n",
    "\n",
    "# Extract the statements and the subject\n",
    "X = data['statement']  # Text data\n",
    "y = data['subject']  # Labels (topics)\n",
    "\n",
    "# Check for missing values in X (input) and y (target)\n",
    "print(\"Missing values in X (input):\", X.isnull().sum())\n",
    "print(\"Missing values in y (target):\", y.isnull().sum())\n",
    "\n",
    "# Remove rows where either X or y has NaN values\n",
    "data = data.dropna(subset=['statement', 'subject'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['statement'], data['subject'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize BERTopic model\n",
    "topic_model = BERTopic()\n",
    "\n",
    "# Fit the model on the training data\n",
    "topic_model.fit(X_train.tolist())\n",
    "\n",
    "# Get embeddings using the transform method for the training set\n",
    "train_embeddings, _ = topic_model.transform(X_train.tolist())\n",
    "\n",
    "# Ensure the embeddings are a 2D array\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Check for missing values in the embeddings and handle them\n",
    "if np.any(np.isnan(train_embeddings)):\n",
    "    print(\"Missing values detected in train_embeddings\")\n",
    "    # Option 1: Fill NaNs with zero (useful for embeddings with missing features)\n",
    "    train_embeddings = np.nan_to_num(train_embeddings, nan=0.0)\n",
    "\n",
    "# Ensure embeddings are 2D\n",
    "if len(train_embeddings.shape) != 2:\n",
    "    print(\"Train embeddings are not 2D, reshaping to 2D.\")\n",
    "    train_embeddings = train_embeddings.reshape(len(train_embeddings), -1)  # Reshaping to 2D\n",
    "\n",
    "# Train the Logistic Regression classifier on the embeddings\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(train_embeddings, y_train)\n",
    "\n",
    "# Get embeddings for the test set using the transform method\n",
    "test_embeddings, _ = topic_model.transform(X_test.tolist())\n",
    "\n",
    "# Ensure the test embeddings are a 2D array\n",
    "test_embeddings = np.array(test_embeddings)\n",
    "\n",
    "# Check for missing values in the embeddings and handle them\n",
    "if np.any(np.isnan(test_embeddings)):\n",
    "    print(\"Missing values detected in test_embeddings\")\n",
    "    # Option 1: Fill NaNs with zero\n",
    "    test_embeddings = np.nan_to_num(test_embeddings, nan=0.0)\n",
    "\n",
    "# Ensure embeddings are 2D\n",
    "if len(test_embeddings.shape) != 2:\n",
    "    print(\"Test embeddings are not 2D, reshaping to 2D.\")\n",
    "    test_embeddings = test_embeddings.reshape(len(test_embeddings), -1)  # Reshaping to 2D\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(test_embeddings)\n",
    "\n",
    "# Evaluate the model using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
