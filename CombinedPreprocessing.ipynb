{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>date</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_description</th>\n",
       "      <th>state_info</th>\n",
       "      <th>true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_false_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13847</td>\n",
       "      <td>5</td>\n",
       "      <td>90 percent of Americans \"support universal bac...</td>\n",
       "      <td>October 2, 2017</td>\n",
       "      <td>government regulation;polls and public opinion...</td>\n",
       "      <td>chris abele</td>\n",
       "      <td>Chris Abele is Milwaukee County Executive, a p...</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>a tweet</td>\n",
       "      <td>\"Universal\" is the term for background checks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13411</td>\n",
       "      <td>1</td>\n",
       "      <td>Last year was one of the deadliest years ever ...</td>\n",
       "      <td>May 19, 2017</td>\n",
       "      <td>after the fact;congress;criminal justice;histo...</td>\n",
       "      <td>thom tillis</td>\n",
       "      <td>Thom Tillis is a Republican who serves as U.S....</td>\n",
       "      <td>north carolina</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>a press release supporting the Back The Blue A...</td>\n",
       "      <td>Sen. Thom Tillis, a North Carolina Republican,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10882</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernie Sanders's plan is \"to raise your taxes ...</td>\n",
       "      <td>October 28, 2015</td>\n",
       "      <td>taxes</td>\n",
       "      <td>chris christie</td>\n",
       "      <td>Chris Christie announced June 6, 2023 that he ...</td>\n",
       "      <td>national</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>Boulder, Colo</td>\n",
       "      <td>Christie said that Sanders’s plan is \"to raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20697</td>\n",
       "      <td>4</td>\n",
       "      <td>Voter ID is supported by an overwhelming major...</td>\n",
       "      <td>December 8, 2021</td>\n",
       "      <td>voter id laws</td>\n",
       "      <td>lee zeldin</td>\n",
       "      <td>Lee Zeldin is a Republican representing New Yo...</td>\n",
       "      <td>new york</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a Tweet</td>\n",
       "      <td>Zeldin claimed voter identification requiremen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6095</td>\n",
       "      <td>2</td>\n",
       "      <td>Says Barack Obama \"robbed Medicare (of) $716 b...</td>\n",
       "      <td>August 12, 2012</td>\n",
       "      <td>federal budget;history;medicare;retirement</td>\n",
       "      <td>mitt romney</td>\n",
       "      <td>Mitt Romney is a U.S. senator from Utah. He ra...</td>\n",
       "      <td>national</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>an interview on \"60 Minutes\"</td>\n",
       "      <td>Romney said, \"There's only one president that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                          statement  \\\n",
       "0  13847      5  90 percent of Americans \"support universal bac...   \n",
       "1  13411      1  Last year was one of the deadliest years ever ...   \n",
       "2  10882      0  Bernie Sanders's plan is \"to raise your taxes ...   \n",
       "3  20697      4  Voter ID is supported by an overwhelming major...   \n",
       "4   6095      2  Says Barack Obama \"robbed Medicare (of) $716 b...   \n",
       "\n",
       "               date                                            subject  \\\n",
       "0   October 2, 2017  government regulation;polls and public opinion...   \n",
       "1      May 19, 2017  after the fact;congress;criminal justice;histo...   \n",
       "2  October 28, 2015                                              taxes   \n",
       "3  December 8, 2021                                      voter id laws   \n",
       "4   August 12, 2012         federal budget;history;medicare;retirement   \n",
       "\n",
       "          speaker                                speaker_description  \\\n",
       "0     chris abele  Chris Abele is Milwaukee County Executive, a p...   \n",
       "1     thom tillis  Thom Tillis is a Republican who serves as U.S....   \n",
       "2  chris christie  Chris Christie announced June 6, 2023 that he ...   \n",
       "3      lee zeldin  Lee Zeldin is a Republican representing New Yo...   \n",
       "4     mitt romney  Mitt Romney is a U.S. senator from Utah. He ra...   \n",
       "\n",
       "       state_info  true_counts  mostly_true_counts  half_true_counts  \\\n",
       "0       wisconsin            1                   4                 5   \n",
       "1  north carolina            0                   2                 7   \n",
       "2        national           21                  20                27   \n",
       "3        new york            1                   2                 0   \n",
       "4        national           31                  33                58   \n",
       "\n",
       "   mostly_false_counts  false_counts  pants_on_fire_counts  \\\n",
       "0                    3             5                     2   \n",
       "1                    3             2                     0   \n",
       "2                   11            17                     8   \n",
       "3                    0             0                     0   \n",
       "4                   35            32                    19   \n",
       "\n",
       "                                             context  \\\n",
       "0                                            a tweet   \n",
       "1  a press release supporting the Back The Blue A...   \n",
       "2                                      Boulder, Colo   \n",
       "3                                            a Tweet   \n",
       "4                       an interview on \"60 Minutes\"   \n",
       "\n",
       "                                       justification  \n",
       "0  \"Universal\" is the term for background checks ...  \n",
       "1  Sen. Thom Tillis, a North Carolina Republican,...  \n",
       "2  Christie said that Sanders’s plan is \"to raise...  \n",
       "3  Zeldin claimed voter identification requiremen...  \n",
       "4  Romney said, \"There's only one president that ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6049\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"LIAR2/train.csv\")\n",
    "display(df.head())\n",
    "print(len(df[\"subject\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lst = []\\ndf[\"subject\"] = df[\"subject\"].fillna(\"NONE\")\\nfor object in df[\"subject\"]:\\n    item = object.split(\";\")\\n    \\n    lst.extend(item)\\n\\nunique_items = set(lst)\\nprint(len(lst))\\nprint(len(unique_items))'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lst = []\n",
    "df[\"subject\"] = df[\"subject\"].fillna(\"NONE\")\n",
    "for object in df[\"subject\"]:\n",
    "    item = object.split(\";\")\n",
    "    \n",
    "    lst.extend(item)\n",
    "\n",
    "unique_items = set(lst)\n",
    "print(len(lst))\n",
    "print(len(unique_items))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m       vectorized_text[vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<UNK>\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m vectorized_text\n\u001b[0;32m---> 29\u001b[0m V_subject \u001b[38;5;241m=\u001b[39m build_descriptive_text_vocab_subject_stateInfo(\u001b[43mdf\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m V_state \u001b[38;5;241m=\u001b[39m build_descriptive_text_vocab_subject_stateInfo(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_info\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(V_subject)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def build_descriptive_text_vocab_subject_stateInfo(input_text):\n",
    "    vocab = set()\n",
    "    vocab.add(\"<UNK>\")\n",
    "    input_text = input_text.lower()\n",
    "    input_text = input_text.fillna(\"<NONE>\")\n",
    "    input_text = input_text.astype(str)\n",
    "\n",
    "    # Build vocabulary\n",
    "    for text in input_text:\n",
    "        for word in text.split(\";\"):\n",
    "            word = word.strip()  # Remove extra spaces\n",
    "            if word:\n",
    "                vocab.add(word)\n",
    "\n",
    "    return {token: i for i, token in enumerate(vocab)}\n",
    "\n",
    "def vectorize_descriptive_text_subject(input_text, vocab):\n",
    "  # Ensure the input is a string\n",
    "  if isinstance(input_text, list):\n",
    "      input_text = \";\".join(input_text)  # Join list into a string\n",
    "  vectorized_text = np.zeros(len(vocab))\n",
    "  for word in input_text.split(\";\"):\n",
    "    if word in vocab:\n",
    "      vectorized_text[vocab[word]] += 1\n",
    "    else:\n",
    "      vectorized_text[vocab[\"<UNK>\"]] += 1\n",
    "  return vectorized_text\n",
    "\n",
    "V_subject = build_descriptive_text_vocab_subject_stateInfo(df[\"subject\"])\n",
    "V_state = build_descriptive_text_vocab_subject_stateInfo(df[\"state_info\"])\n",
    "\n",
    "print(V_subject)\n",
    "test = [\"bankruptcy\", \"infrastructure\", \"well\", \"NakiyahDhariwala\"]\n",
    "check = vectorize_descriptive_text_subject(test, V_subject)\n",
    "print(check)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def build_descriptive_text_vocab(input_text):\\n  vocab = set()\\n  vocab.add(\"<UNK>\")\\n  for text in input_text:\\n    for word in text.split():\\n      word = remove_punctuation(word)\\n      if word:\\n        vocab.add(word)\\n  return {token: i for i, token in enumerate(vocab)}\\n\\ndef vectorize_descriptive_text(input_text, vocab):\\n  vectorized_text = np.zeros(len(vocab))\\n  for word in input_text.split():\\n    word = remove_punctuation(word)\\n    if word in vocab:\\n      vectorized_text[vocab[word]] += 1\\n    else:\\n      vectorized_text[vocab[\"<UNK>\"]] += 1\\n  return vectorized_text\\n\\ndef remove_punctuation(word):\\n    punctuation = set([\".\", \"(\", \")\", \",\", \";\", \"?\", \"!\", \\'\"\\', \":\", \"\\'\"])\\n    while word and word[0] in punctuation:\\n        word = word[1:]\\n    while word and word[-1] in punctuation:\\n        word = word[:-1]\\n    return word.lower()\\n\\ntrain_data = pd.read_csv(\\'LIAR2/train.csv\\')\\n# V = build_descriptive_text_vocab(train_data[\\'statement\\'])\\nV = build_descriptive_text_vocab\\n\\ntest_statement = \"percent chores chores stunt chores stunt chores ontario the\"\\ntest_vector = vectorize_descriptive_text(test_statement, V)\\nprint(test_vector)\\nfor i in test_vector:\\n  print(i)'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ORIGINAL CODE\"\n",
    "\n",
    "\"\"\"def build_descriptive_text_vocab(input_text):\n",
    "  vocab = set()\n",
    "  vocab.add(\"<UNK>\")\n",
    "  for text in input_text:\n",
    "    for word in text.split():\n",
    "      word = remove_punctuation(word)\n",
    "      if word:\n",
    "        vocab.add(word)\n",
    "  return {token: i for i, token in enumerate(vocab)}\n",
    "\n",
    "def vectorize_descriptive_text(input_text, vocab):\n",
    "  vectorized_text = np.zeros(len(vocab))\n",
    "  for word in input_text.split():\n",
    "    word = remove_punctuation(word)\n",
    "    if word in vocab:\n",
    "      vectorized_text[vocab[word]] += 1\n",
    "    else:\n",
    "      vectorized_text[vocab[\"<UNK>\"]] += 1\n",
    "  return vectorized_text\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    punctuation = set([\".\", \"(\", \")\", \",\", \";\", \"?\", \"!\", '\"', \":\", \"'\"])\n",
    "    while word and word[0] in punctuation:\n",
    "        word = word[1:]\n",
    "    while word and word[-1] in punctuation:\n",
    "        word = word[:-1]\n",
    "    return word.lower()\n",
    "\n",
    "train_data = pd.read_csv('LIAR2/train.csv')\n",
    "# V = build_descriptive_text_vocab(train_data['statement'])\n",
    "V = build_descriptive_text_vocab\n",
    "\n",
    "test_statement = \"percent chores chores stunt chores stunt chores ontario the\"\n",
    "test_vector = vectorize_descriptive_text(test_statement, V)\n",
    "print(test_vector)\n",
    "for i in test_vector:\n",
    "  print(i)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCSVDataset(Dataset):\n",
    "#     def __init__(self, csv_file, transform=None):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             csv_file (str): Path to the CSV file containing the data.\n",
    "#             transform (callable, optional): Optional transform to be applied on a sample.\n",
    "#         \"\"\"\n",
    "#         self.data = pd.read_csv(csv_file)  # Load the CSV file\n",
    "#         self.transform = transform\n",
    "\n",
    "#         # Assuming the last column is the label\n",
    "#         self.features = self.data.iloc[:, :-1].values  # All columns except the last one (features)\n",
    "#         self.labels = self.data.iloc[:, -1].values    # The last column (label)\n",
    "\n",
    "#         # Standardize features if necessary\n",
    "#         self.scaler = StandardScaler()\n",
    "#         self.features = self.scaler.fit_transform(self.features)  # Normalize features\n",
    "\n",
    "#     def __len__(self):\n",
    "#         \"\"\"Returns the total number of samples.\"\"\"\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             idx (int): Index of the sample to fetch.\n",
    "#         Returns:\n",
    "#             tuple: (features, label) where features are the input tensor and label is the output tensor.\n",
    "#         \"\"\"\n",
    "#         features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "#         label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "#         if self.transform:\n",
    "#             features = self.transform(features)\n",
    "\n",
    "#         return features, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
