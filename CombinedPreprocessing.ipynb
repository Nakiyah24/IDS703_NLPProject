{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_descriptive_text_vocab(input_text):\n",
    "  vocab = set()\n",
    "  vocab.add(\"<UNK>\")\n",
    "  for text in input_text:\n",
    "    for word in text.split():\n",
    "      word = remove_punctuation(word)\n",
    "      if word:\n",
    "        vocab.add(word)\n",
    "  return {token: i for i, token in enumerate(vocab)}\n",
    "\n",
    "def vectorize_descriptive_text(input_text, vocab):\n",
    "  vectorized_text = np.zeros(len(vocab))\n",
    "  for word in input_text.split():\n",
    "    word = remove_punctuation(word)\n",
    "    if word in vocab:\n",
    "      vectorized_text[vocab[word]] += 1\n",
    "    else:\n",
    "      vectorized_text[vocab[\"<UNK>\"]] += 1\n",
    "  return vectorized_text\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    punctuation = set([\".\", \"(\", \")\", \",\", \";\", \"?\", \"!\", '\"', \":\", \"'\"])\n",
    "    while word and word[0] in punctuation:\n",
    "        word = word[1:]\n",
    "    while word and word[-1] in punctuation:\n",
    "        word = word[:-1]\n",
    "    return word.lower()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CustomCSVDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file containing the data.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)  # Load the CSV file\n",
    "        self.transform = transform\n",
    "\n",
    "        # Assuming the last column is the label\n",
    "        self.features = self.data.iloc[:, :-1].values  # All columns except the last one (features)\n",
    "        self.labels = self.data.iloc[:, -1].values    # The last column (label)\n",
    "\n",
    "        # Standardize features if necessary\n",
    "        self.scaler = StandardScaler()\n",
    "        self.features = self.scaler.fit_transform(self.features)  # Normalize features\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the sample to fetch.\n",
    "        Returns:\n",
    "            tuple: (features, label) where features are the input tensor and label is the output tensor.\n",
    "        \"\"\"\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        return features, label\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
